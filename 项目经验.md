

# 项目概览（一定要大）

## 	平安社区

​		十九大四中全会聚焦新形势下的平安乡村建设工作，包括后来的国务院印发的加强乡村治理指导意见中也指出需建立综合管理服务平台，推荐公共视频安全监控体系化建设。

## 	智能家居		

​		智慧社区的概念得到了极大的延伸，实现从传统领域到科技智能话的转型。核心是公共场合的监控和个人智能家居的美好生活。围绕安全和舒适两个角度。

## 智慧社区云平台

​	智慧社区围绕智能和安全两大生态，建设统一安防平台、综治管控平台、和智能全屋平台三大核心体系。

### 	统一安防平台

​		可视对讲、视频监控、跨境追踪、门禁停车场管控、统一健康码、无接触梯控、烟感雾感告警以及增值服务（出入提醒、全屋联动)

### 	全屋智能平台

​		AI语音联动系统、烟感雾感告警、全屋mixpad精准广告推荐以及增值的（老人小孩跌倒告警）

### 	综治管控平台

​		社区云广播、电动充电桩、智能垃圾桶、智能机器人、广告统一平台、访客、报事报修工单、物业缴费、共享会议室、以及增值服务（代仍垃圾、爱家闹钟）



#### 	数据运营平台

​		通过物联网IOT平台实现各种业务、第三方、地市数据的汇总，通过大数据的实现数据深挖，找出潜在价值，并通过智能分析的方式实现有效信息的精准推荐。比如，人脸识别pad会根据识别的年龄、性别推荐目标群里的价值广告、同时针对老人小孩的各场景出入行为，对家长进行智能的提醒。

#### 	物业管理平台

​		主要是业务服务的体现：包括停车位管理、房屋租赁管理、社区云广播、智能垃圾桶、访客会议室预约、报事报修、物业生活缴费等一系列和小区生活相关的业务。



## 六大场景

​	社区安防

​	社区通行

​	社区运营

​	社区服务

​	社区邻里

​	社区家庭

## 四大硬件套餐

### 	安防套餐

​		（高空抛物+跨境追踪+入侵检测+人脸布控）

### 	通行套餐

​		（云对讲+门禁+停车管理）

### 	全屋套餐

​		（超级面板+灯光秀+烟感雾感紧急告警）

### 	增值套餐

​		（出入提醒+代仍垃圾+机器人快递）

## 中台战略

### 	背景

​		2015年马云到芬兰的supercell总部参观，200个人的团队，每个游戏4-5个人，十款创意并行，最后只推出一款皇室战争。感叹大中台小前台模式下，对于市场的不断试错，快速演变的中台模式。回国以后提出3年做中台，要从18年开始阿里将从IT时代进入DT时代，从阿里的战略来看18年成立的阿里云中台事业群，就是把阿里云和中台业务整合在一起。（19年不管是美团、腾讯还是滴滴都纷纷加入的中台大战）。

### 	里程

​		为了更好应对市场的不确定性，在变动的市场中更快的试错和创新，在大厂中台战略的羊群效应下，部分一线的小创业公司也在纷纷效仿，通过不断的小前台实现的MVP不断的迭代自己产品，大型国企在固本增元的思想指导下，也纷纷通过中台作为抓手，通过统一的核心能力去根据场景孵化更新更轻的产品。

### 	移动

​		19年上半年，通过将智慧楼宇中已有的能力进行整合，下半年形成了智慧社区云平台大中台和各地省公司小前台的部署战略，20年上半年，通过集团战略+疫情的原因，社区一共在北京、广东、新疆、四川、甘肃、海南、浙江等省已落地四个省级前台。

#### 		优势

​		大中台和小前台模式通过本地驱动、核心业务支撑带来了项目规模的急剧扩张，目前规模是落地3万个小区，共计1000万社区用户，日活30万左右。

#### 		问题

​		大中台由于各地市客户、领导、集团等多方面的需求挤压，全部的需求都做完要排期到一年以后，由于每个功能的修改都会涉及到基础能力的升级，为了保证稳定性，即时很小的修改也需要做大规模的验证测试。不可避免的在绩效考核中，既要保证稳定不被投诉、又要保证即时的响应，不被兄弟产品线甩锅。从我现在的经验看来，做好中台必须有强大的领导和远大的愿景支撑，不然最终的结果不是被业务拖垮就是大中台的愿景事与愿违。

#### 		思考

​		我觉得中台最好的模式，应该首先是自顶向下的，领导的规划和部门的愿景能与大中台的战略匹配上，然后首先从0到1的过程，通过部门整合全部的能力，全力将中台的MVP模型落地出来，然后在服务一到两个业务，同时还要指定长期的考核指标：如Q1考虑业务架构的全面性，Q2考虑业务架构的可用性，Q3考虑接入的业务数量 Q4考核满意度和收益。只有这样才能把整个模式盘活起来，如果一开始就没有长远的打算，中台的战略很容易成为各方利益相争的炮灰。



# 抽象思维

## 	业务中台

### 		业务抽象

​			核心开放能力：通讯录、短信、推送、通知、支付

### 		业务边界

​			安防：cam、access、aiHouse

​			通行：NB、visitor、car

​			服务：dhcdz、xwygb、pay、value、order

### 		业务体系

​			链路追踪、鉴权管理、统一日志、可视化

### 		业务壁垒

​			高可用

​				限流熔断、灰度发布、业务双活

​			高性能

​				分布式集群、缓存、队列、CDN

​			高安全

​				渗透测试、漏洞扫描、防火墙策略

## 	方法论

### 		Discovery

​				考虑企业战略，分析客户需求，制定产品目标

​					由外到内：竞争对手的方案，为什么做，以后怎么发展，如何去优化。

​					自上而下：基于公司的战略，考虑自身能力和所处环境。

​					自下而上：从资源、历史问题、优先级出发，形成一套可行性实施方法。

### 		Define

​				基于收集的信息，综合跨业务线的抽象能力和服务，先做什么后做什么，怎么做

​					设计新的架构，重点设计解决痛点问题。

​					拆分业务领域，重点划分工作临界上下文。

### 		Design

​				详细的业务设计，功能设计，交付计划，考核计划

​					产品愿景，产品形态，相关竞品方案对比，价值、优势、收益

​					梳理业务范围，要知道电商领域四大流（信息流、商流、资金流、物流）

​					MVP最小可用比，让客户和老大看到结果，最后通编写story把故事编圆

### 		Delivery

​				交付阶段，根据反馈及时调整中台战略，减少损失和增大收益

​					合理制定每个阶段的绩效考核目标：

​				40%稳定+25%业务创新+20%服务接入+15%用户满意度



# 架构实践

## 云平台三方对接图

​	<img src="C:\Users\Administrator\Downloads\广东云平台三方对接图.png" alt="广东云平台三方对接图"  />

## 省级平台交互部署图

![image-20201115112422526](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20201115112422526.png)

## 社区云平台架构图![社区云平台架构](C:\Users\Admin\Downloads\社区云平台架构.png)

# 重点问题

## 架构设计

故障及应对办法

熔断、容灾、流量迁移、多机房多活

架构设计的解耦

## 架构优化

多线程、异步、水平和垂直扩展

预处理、缓存、分区

## 责任心

加班、总结、分享

业界最新趋势，蚂蚁金服全面ServiceMesh

需要根据实际情况，做出一个技术方案选型。



STAR法则

研发xxx，配合xx系统实现xxx功能，性能提升了xxx

我在项目中负责了xxx工作

交代工作具体的实现，利用xxx技术，用了xxx时间，达到了xxx标准

实现了什么效果，用户数、tps、连接数等实际效果



例如：比如在数据量非常大的场景下，通过优化 Redis 存储结构，减少了 70% 的 Redis 使用容量；比如对查询接口应用双发功能使 p999 降低了 60%；再比如使用了 Trace 功能来快速定位问题，通过增加二级缓存，对后端服务的调用请求从 7000qps 降低到 600qps。

现在项目 QPS 不高，某些任务是同步处理的，会有一定效率问题，这些处理步骤是可以异步执行的，如果请求量级增加，可以考虑使用 kafka 进行异步处理。处理时还应该考虑消息重复的问题，可以把处理逻辑设计成幂等性的

考虑到异步任务有重发机制，基于性能的考虑，去掉了kafka的ack应答。如果换做要求严格不丢失的场景，我会使用同步应答， 并且通过幂等性提升消息的可靠等级

准备的问题

您看我这次面试中哪些地方需要改进

业务线工作内容，使用了哪些技术栈

Netty介绍

总用户数、总连接数、在线用户数、用线程安全的atom*

Redis可以异步回刷，tomcat可以使用guavacache返回默认值。

blpop阻塞队列，srandommember随机抽奖，sinter共同关注

bitmap来保持用户的签到信息、保存在线状态、标记vip用户（用户+偏移量+状态）

set保存昵称，hgetall会发生redis慢查，可使用布隆过滤器来判断

可以使用慢查询日志、配合monitor来查询问题来源

**字典库**

key-Value 业务表存 code 显示 文字

拉勾早期将字典库，设置了maxmemory，并设置缓存淘汰策略为allkeys-lru

结果造成字典库某些字段失效，缓存击穿 ， DB压力剧增，差点宕机。

分析：

字典库 ： Redis做DB使用，要保证数据的完整性

maxmemory设置较小，采用allkeys-lru，会对没有经常访问的字典库随机淘汰

当再次访问时会缓存击穿，请求会打到DB上。

解决方案：

1、不设置maxmemory

2、使用noenviction策略

主从+哨兵保证高可用



# 自我介绍

面试官你好，我叫刘苏宏，本科毕业于西北工业大学，硕士毕业于中国科学技术大学，都是软件工程专业。毕业以后来到了中国移动研究院终端部，后被独立成杭州研发中心融合通信系统部，

首先参与研发了集团内部第一款小移人家即时通信APP，其中负责openfire通信模块的改造，主要做了两个事情：1是将群聊容量从200人提升到500人。2是利用时间流的标志保证了多终端历史消息的一致。

第二块是使用php从0到1搭建了基于ci框架《自主开发大赛官网》，印象较深的一是使用facebook的hhvm替代原生php7fpm，性能提升200%。二是结合java支撑高并发场景下投票活动，主要是通过kafka将机票和审核解耦。

第三块是独立承担小移党建的后台研发工作，这里也是从0到十万并发的项目。主要是通过netty的websocket实现的党建知识pk系统。主要使用到了redis的zset和分布式锁、ThreadLocal、锁优化、hashedTimerWheel的使用。实现最高并发5w长连接同时在线，上线一个月累计答题超1亿五千万次。是当时公司成立以来的最大并发的项目，而由于规划的问题，整个项目后端是我一个人承担完成。

​	19年7月至今是在智慧楼宇系统基础上，架构了一套基于springcloud框架的智慧社区标准化云平台，这半年主要是重构了config实现基于SpringCloudStream的自动发布、使用completableFuture优化了厂商平台数据延迟问题、以及基于OAuth2.0建立了一套社区生态开放体系。最近一个月主要是在做基于docker+k8s的aop发布系统，和石桥与园区机房的业务双活。目前社区平台累计服务社区2w、用户300w，日活30w左右。

​	有一次性能问题是由于定时任务的死锁导致的内存溢出oom

